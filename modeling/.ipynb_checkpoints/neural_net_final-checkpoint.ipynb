{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/hourlycalls_weather_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: features[N:M] actually is features[N] through features [M-1] -- it's non-inclusive\n",
    "\n",
    "# features[0]       --- 'CAD_INCIDENT_ID'                                            ---- DROP (only an index)\n",
    "# features[1]       --- 'INITIAL_SEVERITY_LEVEL_CODE'\n",
    "# features[2]       --- 'FINAL_SEVERITY_LEVEL_CODE'\n",
    "# features[3]       --- 'FIRST_ASSIGNMENT_DATETIME'                                  ---- DROP\n",
    "# features[4]       --- 'VALID_DISPATCH_RSPNS_TIME_INDC' \n",
    "# features[5]       --- 'DISPATCH_RESPONSE_SECONDS_QY'                               ---- DROP\n",
    "# features[6]       --- 'FIRST_ACTIVATION_DATETIME' \n",
    "# features[7]       --- 'VALID_INCIDENT_RSPNS_TIME_INDC'\n",
    "# features[8]       --- 'INCIDENT_RESPONSE_SECONDS_QY'                               ------> y\n",
    "# features[9]       --- 'INCIDENT_TRAVEL_TM_SECONDS_QY'\n",
    "# features[10]      --- 'INCIDENT_CLOSE_DATETIME' \n",
    "# features[11]      --- 'HELD_INDICATOR' \n",
    "# features[12]      --- 'REOPEN_INDICATOR'\n",
    "# features[13]      --- 'SPECIAL_EVENT_INDICATOR' \n",
    "# features[14]      --- 'STANDBY_INDICATOR'\n",
    "# features[15]      --- 'TRANSFER_INDICATOR'\n",
    "# features[16:96]   --- 'INITIAL_CALL_TYPE' dummies\n",
    "# features[96:186]  --- 'FINAL_CALL_TYPE' dummies\n",
    "# features[186:195] --- 'INCIDENT_DISPOSITION_CODE' dummies\n",
    "# features[195:198] --- 'BOROUGH' dummies\n",
    "# features[198:230] --- 'INCIDENT_DISPATCH_AREA' dummies\n",
    "# features[230:594] --- 'ZIPCODE' dummies\n",
    "# features[594:670] --- 'POLICEPRECINCT' dummies\n",
    "# features[670:720] --- 'CITYCOUNCILDISTRICT' dummies\n",
    "# features[720:788] --- 'COMMUNITYDISTRICT' dummies\n",
    "# features[788:819] --- 'COMMUNITYSCHOOLDISTRICT' dummies\n",
    "# features[829:831] --- 'CONGRESSIONALDISTRICT' dummies\n",
    "# features[831]     --- 'CALL_YEAR'\n",
    "# features[832]     --- 'CALL_DAY'\n",
    "# features[833]     --- 'CALL_TIME'\n",
    "# features[834]     --- 'CALL_UTC'\n",
    "# features[835:846] --- 'CALL_MONTH' dummies\n",
    "# features[846]     --- 'CALL_MONTH' (numeric)\n",
    "# features[847]     --- 'AWIND'\n",
    "# features[848]     --- 'PRCP'\n",
    "# features[849]     --- 'SNOW'\n",
    "# features[850]     --- 'SNWD'\n",
    "# features[851]     --- 'TMAX'\n",
    "# features[852]     --- 'TMIN'\n",
    "# features[853]     --- 'TAVG_CALC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25465.000000\n",
       "mean         0.134018\n",
       "std          0.393702\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.050000\n",
       "max          5.810000\n",
       "Name: PRCP, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PRCP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data and Remove features that would outright count up to the total number of calls\n",
    "features = ['Unnamed: 0', 'Unnamed: 0.1', 'BRONX', 'BROOKLYN', 'MANHATTAN', 'QUEENS', \n",
    "            'RICHMOND / STATEN ISLAND', 'UNKNOWN', 'NAME', 'num_calls', 'DATE']\n",
    "\n",
    "\n",
    "X = df.drop(columns= features)\n",
    "\n",
    "X = X.fillna(X['AWND'].mean())\n",
    "\n",
    "X = pd.get_dummies(data = X, columns = ['STATION'], drop_first = True)\n",
    "\n",
    "y = df['num_calls']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'month', 'day', 'hour', 'AWND', 'PRCP', 'SNOW', 'SNWD', 'TMAX',\n",
       "       'TMIN', 'TAVG_CALC', 'Traffic Incidents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X['AWND'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.5144276829337519\n",
      "Testing: 0.5188483809790554\n"
     ]
    }
   ],
   "source": [
    "# linear regression is go to for modelling since it is the simplest in this case\n",
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(X_train_sc, y_train)\n",
    "\n",
    "print(f'Training: {linreg.score(X_train_sc, y_train)}')\n",
    "print(f'Testing: {linreg.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not seem likely, not sure yet why this is the result but there is definitely something not quite right here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.5120454233455058\n",
      "Testing: 0.5163948752009309\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(max_iter = 10_000)\n",
    "\n",
    "lasso.fit(X_train_sc, y_train)\n",
    "\n",
    "print(f'Training: {lasso.score(X_train_sc, y_train)}')\n",
    "print(f'Testing: {lasso.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.5144276816478912\n",
      "Testing: 0.5188484599641534\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "ridge.fit(X_train_sc, y_train)\n",
    "\n",
    "print(f'Training: {ridge.score(X_train_sc, y_train)}')\n",
    "print(f'Testing: {ridge.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I realized the issue here.  Left in a lot of data that was used to create our new dependent variable.  This has been corrected more or less.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Neural Nets: Predicting Call Volumes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19098, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 13942.4786 - mae: 100.1119 - val_loss: 1877.7753 - val_mae: 34.6136\n",
      "Epoch 2/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1819.1523 - mae: 34.0199 - val_loss: 1572.8887 - val_mae: 31.7310\n",
      "Epoch 3/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1497.1460 - mae: 30.9463 - val_loss: 1367.4949 - val_mae: 29.5760\n",
      "Epoch 4/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1320.3213 - mae: 28.7312 - val_loss: 1122.4434 - val_mae: 26.4789\n",
      "Epoch 5/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1051.2029 - mae: 25.5746 - val_loss: 885.1971 - val_mae: 23.6635\n",
      "Epoch 6/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 850.3890 - mae: 22.8820 - val_loss: 748.0832 - val_mae: 21.8380\n",
      "Epoch 7/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 745.0198 - mae: 21.0676 - val_loss: 652.3526 - val_mae: 19.7200\n",
      "Epoch 8/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 660.0072 - mae: 19.8149 - val_loss: 622.9047 - val_mae: 19.5427\n",
      "Epoch 9/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 632.5557 - mae: 19.3582 - val_loss: 618.7515 - val_mae: 19.8063\n",
      "Epoch 10/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 624.0267 - mae: 19.2987 - val_loss: 583.3065 - val_mae: 18.7751\n",
      "Epoch 11/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 622.3892 - mae: 18.9952 - val_loss: 594.1969 - val_mae: 19.2851\n",
      "Epoch 12/250\n",
      "191/191 [==============================] - 0s 974us/step - loss: 577.9605 - mae: 18.5726 - val_loss: 571.4675 - val_mae: 18.6194\n",
      "Epoch 13/250\n",
      "191/191 [==============================] - 0s 982us/step - loss: 588.0250 - mae: 18.8318 - val_loss: 563.7725 - val_mae: 18.5206\n",
      "Epoch 14/250\n",
      "191/191 [==============================] - 0s 959us/step - loss: 579.5719 - mae: 18.4874 - val_loss: 562.1815 - val_mae: 17.9538\n",
      "Epoch 15/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 563.6981 - mae: 18.3146 - val_loss: 550.5130 - val_mae: 18.0602\n",
      "Epoch 16/250\n",
      "191/191 [==============================] - 0s 993us/step - loss: 575.9979 - mae: 18.4073 - val_loss: 541.1273 - val_mae: 17.8092\n",
      "Epoch 17/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 564.1325 - mae: 18.1176 - val_loss: 546.5602 - val_mae: 18.1063\n",
      "Epoch 18/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 566.6153 - mae: 18.2493 - val_loss: 534.5551 - val_mae: 17.7102\n",
      "Epoch 19/250\n",
      "191/191 [==============================] - 0s 976us/step - loss: 593.5385 - mae: 18.2527 - val_loss: 540.3757 - val_mae: 17.5840\n",
      "Epoch 20/250\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 549.1191 - mae: 17.8274 - val_loss: 532.5987 - val_mae: 17.6512\n",
      "Epoch 21/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 540.0316 - mae: 17.8760 - val_loss: 527.2061 - val_mae: 17.5720\n",
      "Epoch 22/250\n",
      "191/191 [==============================] - 0s 985us/step - loss: 542.6004 - mae: 17.8862 - val_loss: 530.7764 - val_mae: 17.6259\n",
      "Epoch 23/250\n",
      "191/191 [==============================] - 0s 992us/step - loss: 534.0433 - mae: 17.6387 - val_loss: 543.1111 - val_mae: 17.6499\n",
      "Epoch 24/250\n",
      "191/191 [==============================] - 0s 996us/step - loss: 544.4505 - mae: 17.7291 - val_loss: 519.9136 - val_mae: 17.3867\n",
      "Epoch 25/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 531.4430 - mae: 17.7129 - val_loss: 525.9185 - val_mae: 17.5990\n",
      "Epoch 26/250\n",
      "191/191 [==============================] - 0s 973us/step - loss: 522.8785 - mae: 17.6069 - val_loss: 525.5058 - val_mae: 17.3833\n",
      "Epoch 27/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 534.3658 - mae: 17.7624 - val_loss: 532.1099 - val_mae: 17.6172\n",
      "Epoch 28/250\n",
      "191/191 [==============================] - 0s 993us/step - loss: 541.9755 - mae: 17.6296 - val_loss: 514.4888 - val_mae: 17.2875\n",
      "Epoch 29/250\n",
      "191/191 [==============================] - 0s 996us/step - loss: 527.3923 - mae: 17.5676 - val_loss: 520.7384 - val_mae: 17.4649\n",
      "Epoch 30/250\n",
      "191/191 [==============================] - 0s 991us/step - loss: 538.6420 - mae: 17.6530 - val_loss: 516.9797 - val_mae: 17.3198\n",
      "Epoch 31/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 529.3803 - mae: 17.5265 - val_loss: 508.9148 - val_mae: 17.1237\n",
      "Epoch 32/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 521.7241 - mae: 17.3970 - val_loss: 518.0917 - val_mae: 17.4444\n",
      "Epoch 33/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 532.8556 - mae: 17.3900 - val_loss: 533.5139 - val_mae: 17.4876\n",
      "Epoch 34/250\n",
      "191/191 [==============================] - 0s 987us/step - loss: 517.0210 - mae: 17.3572 - val_loss: 509.5804 - val_mae: 17.2746\n",
      "Epoch 35/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 528.5858 - mae: 17.3290 - val_loss: 511.4766 - val_mae: 17.4699\n",
      "Epoch 36/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 516.1522 - mae: 17.3508 - val_loss: 523.4092 - val_mae: 17.1938\n",
      "Epoch 37/250\n",
      "191/191 [==============================] - 0s 988us/step - loss: 524.0404 - mae: 17.3616 - val_loss: 509.7583 - val_mae: 17.0279\n",
      "Epoch 38/250\n",
      "191/191 [==============================] - 0s 991us/step - loss: 498.0336 - mae: 17.1279 - val_loss: 513.1421 - val_mae: 17.3660\n",
      "Epoch 39/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 498.6257 - mae: 17.1393 - val_loss: 516.7812 - val_mae: 17.5191\n",
      "Epoch 40/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 533.2050 - mae: 17.4628 - val_loss: 504.4351 - val_mae: 17.2572\n",
      "Epoch 41/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 499.5464 - mae: 17.2409 - val_loss: 515.0407 - val_mae: 17.4370\n",
      "Epoch 42/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 504.7368 - mae: 17.1103 - val_loss: 529.0040 - val_mae: 18.0176\n",
      "Epoch 43/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 506.8925 - mae: 17.3143 - val_loss: 505.1422 - val_mae: 16.9379\n",
      "Epoch 44/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 505.4804 - mae: 17.2022 - val_loss: 497.7855 - val_mae: 17.0416\n",
      "Epoch 45/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 513.4607 - mae: 17.1356 - val_loss: 505.3140 - val_mae: 17.1372\n",
      "Epoch 46/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 497.1458 - mae: 17.1440 - val_loss: 509.8072 - val_mae: 17.4286\n",
      "Epoch 47/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 512.3645 - mae: 17.1943 - val_loss: 506.2478 - val_mae: 17.0944\n",
      "Epoch 48/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 486.0982 - mae: 16.9205 - val_loss: 502.2195 - val_mae: 17.1333\n",
      "Epoch 49/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 501.5653 - mae: 17.1148 - val_loss: 501.4179 - val_mae: 17.1139\n",
      "Epoch 50/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 482.1697 - mae: 16.9176 - val_loss: 499.9557 - val_mae: 17.0565\n",
      "Epoch 51/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 506.3033 - mae: 17.1096 - val_loss: 515.5939 - val_mae: 17.3440\n",
      "Epoch 52/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 507.6477 - mae: 17.1376 - val_loss: 507.7193 - val_mae: 16.9881\n",
      "Epoch 53/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 500.1653 - mae: 16.9870 - val_loss: 501.2372 - val_mae: 17.1415\n",
      "Epoch 54/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 502.8826 - mae: 17.0868 - val_loss: 499.1226 - val_mae: 16.9177\n",
      "Epoch 55/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 492.4760 - mae: 16.8825 - val_loss: 500.1646 - val_mae: 17.0337\n",
      "Epoch 56/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 484.1589 - mae: 16.8119 - val_loss: 506.7292 - val_mae: 17.2202\n",
      "Epoch 57/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 501.9687 - mae: 17.1041 - val_loss: 505.1262 - val_mae: 17.3808\n",
      "Epoch 58/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 495.0856 - mae: 16.9208 - val_loss: 505.7079 - val_mae: 17.1515\n",
      "Epoch 59/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 501.3403 - mae: 17.0566 - val_loss: 503.6364 - val_mae: 17.1522\n",
      "Epoch 60/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 491.1718 - mae: 17.0410 - val_loss: 500.3832 - val_mae: 16.8378\n",
      "Epoch 61/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 494.9299 - mae: 16.9400 - val_loss: 496.5108 - val_mae: 16.9495\n",
      "Epoch 62/250\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 492.7127 - mae: 16.9545 - val_loss: 501.7770 - val_mae: 16.9734\n",
      "Epoch 63/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 489.0364 - mae: 16.8678 - val_loss: 505.1617 - val_mae: 17.0605\n",
      "Epoch 64/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 490.2284 - mae: 17.0140 - val_loss: 501.4715 - val_mae: 17.0342\n",
      "Epoch 65/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 482.9153 - mae: 16.7602 - val_loss: 501.6818 - val_mae: 17.0001\n",
      "Epoch 66/250\n",
      "191/191 [==============================] - 0s 991us/step - loss: 488.1612 - mae: 16.9718 - val_loss: 497.4446 - val_mae: 17.1416\n",
      "Epoch 67/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 500.7758 - mae: 16.9952 - val_loss: 508.4842 - val_mae: 17.2426\n",
      "Epoch 68/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 497.4207 - mae: 16.8676 - val_loss: 497.9668 - val_mae: 17.0750\n",
      "Epoch 69/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 486.9046 - mae: 16.9523 - val_loss: 516.4440 - val_mae: 17.4854\n",
      "Epoch 70/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 488.6362 - mae: 17.0514 - val_loss: 494.9440 - val_mae: 17.0719\n",
      "Epoch 71/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 494.0929 - mae: 17.0442 - val_loss: 492.1282 - val_mae: 17.0775\n",
      "Epoch 72/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 491.2025 - mae: 16.9872 - val_loss: 504.2328 - val_mae: 17.1907\n",
      "Epoch 73/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 482.3787 - mae: 16.7534 - val_loss: 500.5985 - val_mae: 17.1540\n",
      "Epoch 74/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 490.1490 - mae: 16.9656 - val_loss: 505.7710 - val_mae: 17.1355\n",
      "Epoch 75/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 475.2590 - mae: 16.8280 - val_loss: 497.9571 - val_mae: 17.1694\n",
      "Epoch 76/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 498.9676 - mae: 16.8908 - val_loss: 493.2017 - val_mae: 17.0525\n",
      "Epoch 77/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 488.9951 - mae: 16.7814 - val_loss: 503.9633 - val_mae: 17.1004\n",
      "Epoch 78/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 498.2328 - mae: 16.9699 - val_loss: 489.7330 - val_mae: 16.8315\n",
      "Epoch 79/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 478.3073 - mae: 16.6261 - val_loss: 495.0402 - val_mae: 17.2331\n",
      "Epoch 80/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 479.4117 - mae: 16.8464 - val_loss: 494.1630 - val_mae: 17.0382\n",
      "Epoch 81/250\n",
      "191/191 [==============================] - 0s 982us/step - loss: 472.0561 - mae: 16.7322 - val_loss: 487.6565 - val_mae: 16.9382\n",
      "Epoch 82/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 481.8837 - mae: 16.6949 - val_loss: 498.8720 - val_mae: 17.0150\n",
      "Epoch 83/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 477.4979 - mae: 16.8005 - val_loss: 491.3570 - val_mae: 17.1040\n",
      "Epoch 84/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 485.3567 - mae: 16.7409 - val_loss: 493.8027 - val_mae: 17.0586\n",
      "Epoch 85/250\n",
      "191/191 [==============================] - 0s 997us/step - loss: 479.7177 - mae: 16.8775 - val_loss: 494.4673 - val_mae: 17.0288\n",
      "Epoch 86/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 494.1785 - mae: 16.8657 - val_loss: 495.1697 - val_mae: 17.0332\n",
      "Epoch 87/250\n",
      "191/191 [==============================] - 0s 968us/step - loss: 504.8089 - mae: 16.9639 - val_loss: 490.0061 - val_mae: 17.0184\n",
      "Epoch 88/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 475.0192 - mae: 16.7592 - val_loss: 497.5148 - val_mae: 17.1099\n",
      "Epoch 89/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 493.8940 - mae: 16.7543 - val_loss: 493.3125 - val_mae: 17.1186\n",
      "Epoch 90/250\n",
      "191/191 [==============================] - 0s 998us/step - loss: 493.3748 - mae: 16.8768 - val_loss: 499.3348 - val_mae: 17.2553\n",
      "Epoch 91/250\n",
      "191/191 [==============================] - 0s 991us/step - loss: 483.0178 - mae: 16.7569 - val_loss: 491.3371 - val_mae: 16.9345\n",
      "Epoch 92/250\n",
      "191/191 [==============================] - 0s 996us/step - loss: 475.0014 - mae: 16.7190 - val_loss: 497.6882 - val_mae: 17.1617\n",
      "Epoch 93/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 481.7322 - mae: 16.9809 - val_loss: 488.7377 - val_mae: 16.8197\n",
      "Epoch 94/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 483.5136 - mae: 16.8507 - val_loss: 490.6922 - val_mae: 17.1238\n",
      "Epoch 95/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 471.0961 - mae: 16.5993 - val_loss: 497.7856 - val_mae: 17.0261\n",
      "Epoch 96/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 490.3793 - mae: 16.8725 - val_loss: 489.4944 - val_mae: 17.0270\n",
      "Epoch 97/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 487.5038 - mae: 16.7795 - val_loss: 494.4900 - val_mae: 17.2608\n",
      "Epoch 98/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 473.5857 - mae: 16.7721 - val_loss: 512.3329 - val_mae: 17.4391\n",
      "Epoch 99/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 465.9276 - mae: 16.5460 - val_loss: 491.3563 - val_mae: 16.9884\n",
      "Epoch 100/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 497.9658 - mae: 16.9328 - val_loss: 491.7274 - val_mae: 16.9836\n",
      "Epoch 101/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 462.2522 - mae: 16.5060 - val_loss: 490.8219 - val_mae: 17.1969\n",
      "Epoch 102/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 486.5498 - mae: 16.9005 - val_loss: 494.4905 - val_mae: 16.9443\n",
      "Epoch 103/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 483.7115 - mae: 16.7543 - val_loss: 487.9203 - val_mae: 16.9364\n",
      "Epoch 104/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 466.3014 - mae: 16.5165 - val_loss: 490.5227 - val_mae: 17.1789\n",
      "Epoch 105/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 470.4138 - mae: 16.7988 - val_loss: 498.0023 - val_mae: 16.9598\n",
      "Epoch 106/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 484.5987 - mae: 16.7273 - val_loss: 497.3141 - val_mae: 17.2003\n",
      "Epoch 107/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 463.3391 - mae: 16.5964 - val_loss: 491.1839 - val_mae: 16.9100\n",
      "Epoch 108/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 482.8392 - mae: 16.8042 - val_loss: 488.2090 - val_mae: 17.0751\n",
      "Epoch 109/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 460.8512 - mae: 16.5365 - val_loss: 491.1752 - val_mae: 17.1979\n",
      "Epoch 110/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.3867 - mae: 16.7289 - val_loss: 484.3992 - val_mae: 16.9477\n",
      "Epoch 111/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 460.7528 - mae: 16.5780 - val_loss: 494.5663 - val_mae: 16.9821\n",
      "Epoch 112/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 457.3885 - mae: 16.5457 - val_loss: 497.4839 - val_mae: 17.3455\n",
      "Epoch 113/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 478.8152 - mae: 16.7177 - val_loss: 490.6415 - val_mae: 17.0413\n",
      "Epoch 114/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 475.3610 - mae: 16.6292 - val_loss: 483.4166 - val_mae: 17.0334\n",
      "Epoch 115/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 479.7442 - mae: 16.8483 - val_loss: 491.9018 - val_mae: 17.1764\n",
      "Epoch 116/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 480.2096 - mae: 16.6907 - val_loss: 481.0465 - val_mae: 16.9367\n",
      "Epoch 117/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 469.5157 - mae: 16.7016 - val_loss: 485.4219 - val_mae: 16.9592\n",
      "Epoch 118/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 475.9611 - mae: 16.6404 - val_loss: 482.9199 - val_mae: 16.8728\n",
      "Epoch 119/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.6128 - mae: 16.5578 - val_loss: 484.9593 - val_mae: 16.8947\n",
      "Epoch 120/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 465.0203 - mae: 16.4977 - val_loss: 489.1037 - val_mae: 17.1330\n",
      "Epoch 121/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 483.1837 - mae: 16.9181 - val_loss: 498.2528 - val_mae: 17.0820\n",
      "Epoch 122/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 476.3568 - mae: 16.8152 - val_loss: 484.3879 - val_mae: 16.7798\n",
      "Epoch 123/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 458.7916 - mae: 16.4845 - val_loss: 481.6702 - val_mae: 16.7987\n",
      "Epoch 124/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 470.8480 - mae: 16.6909 - val_loss: 487.5579 - val_mae: 17.0565\n",
      "Epoch 125/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 477.2858 - mae: 16.6843 - val_loss: 483.6084 - val_mae: 16.9200\n",
      "Epoch 126/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 469.1851 - mae: 16.5811 - val_loss: 486.8746 - val_mae: 16.7596\n",
      "Epoch 127/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 454.4708 - mae: 16.3282 - val_loss: 488.1039 - val_mae: 16.7188\n",
      "Epoch 128/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.0199 - mae: 16.7552 - val_loss: 487.5686 - val_mae: 17.0091\n",
      "Epoch 129/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 452.1473 - mae: 16.3681 - val_loss: 485.6320 - val_mae: 17.1257\n",
      "Epoch 130/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 475.9186 - mae: 16.7459 - val_loss: 492.9204 - val_mae: 17.2918\n",
      "Epoch 131/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 494.0188 - mae: 16.8798 - val_loss: 484.7741 - val_mae: 16.8545\n",
      "Epoch 132/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 465.3154 - mae: 16.5343 - val_loss: 524.0346 - val_mae: 17.6963\n",
      "Epoch 133/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 472.2990 - mae: 16.6924 - val_loss: 484.2278 - val_mae: 17.0098\n",
      "Epoch 134/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 467.3655 - mae: 16.4826 - val_loss: 505.8081 - val_mae: 17.5236\n",
      "Epoch 135/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 464.3038 - mae: 16.6189 - val_loss: 479.0432 - val_mae: 16.8068\n",
      "Epoch 136/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 473.3239 - mae: 16.4580 - val_loss: 477.1198 - val_mae: 16.7740\n",
      "Epoch 137/250\n",
      "191/191 [==============================] - 0s 952us/step - loss: 460.1413 - mae: 16.3296 - val_loss: 477.2711 - val_mae: 16.7806\n",
      "Epoch 138/250\n",
      "191/191 [==============================] - 0s 998us/step - loss: 457.2026 - mae: 16.5065 - val_loss: 486.9275 - val_mae: 17.0453\n",
      "Epoch 139/250\n",
      "191/191 [==============================] - 0s 928us/step - loss: 457.3566 - mae: 16.5231 - val_loss: 478.9100 - val_mae: 16.8935\n",
      "Epoch 140/250\n",
      "191/191 [==============================] - 0s 908us/step - loss: 456.5797 - mae: 16.4264 - val_loss: 498.5482 - val_mae: 17.3996\n",
      "Epoch 141/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.6248 - mae: 16.6856 - val_loss: 483.8177 - val_mae: 16.8563\n",
      "Epoch 142/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 464.6012 - mae: 16.5909 - val_loss: 476.3594 - val_mae: 16.8448\n",
      "Epoch 143/250\n",
      "191/191 [==============================] - 0s 930us/step - loss: 453.1636 - mae: 16.2128 - val_loss: 477.9844 - val_mae: 16.8070\n",
      "Epoch 144/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 454.5729 - mae: 16.4047 - val_loss: 479.8815 - val_mae: 16.8784\n",
      "Epoch 145/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 454.1392 - mae: 16.3884 - val_loss: 481.2706 - val_mae: 16.8647\n",
      "Epoch 146/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 470.2291 - mae: 16.6645 - val_loss: 476.2463 - val_mae: 16.9220\n",
      "Epoch 147/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 464.7228 - mae: 16.5204 - val_loss: 475.7193 - val_mae: 16.8048\n",
      "Epoch 148/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 468.2698 - mae: 16.5086 - val_loss: 478.5934 - val_mae: 17.0430\n",
      "Epoch 149/250\n",
      "191/191 [==============================] - 0s 993us/step - loss: 462.0483 - mae: 16.5153 - val_loss: 490.3723 - val_mae: 17.1721\n",
      "Epoch 150/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 459.4184 - mae: 16.5051 - val_loss: 487.3745 - val_mae: 17.1955\n",
      "Epoch 151/250\n",
      "191/191 [==============================] - 0s 971us/step - loss: 456.2612 - mae: 16.5216 - val_loss: 476.1114 - val_mae: 16.7238\n",
      "Epoch 152/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 449.7688 - mae: 16.2846 - val_loss: 482.8285 - val_mae: 16.9099\n",
      "Epoch 153/250\n",
      "191/191 [==============================] - 0s 937us/step - loss: 445.3521 - mae: 16.2399 - val_loss: 483.1413 - val_mae: 17.0332\n",
      "Epoch 154/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 446.0493 - mae: 16.3205 - val_loss: 490.0918 - val_mae: 17.3380\n",
      "Epoch 155/250\n",
      "191/191 [==============================] - 0s 998us/step - loss: 446.6005 - mae: 16.3012 - val_loss: 477.1355 - val_mae: 16.7975\n",
      "Epoch 156/250\n",
      "191/191 [==============================] - 0s 962us/step - loss: 448.2524 - mae: 16.2291 - val_loss: 483.4303 - val_mae: 16.8333\n",
      "Epoch 157/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 450.7875 - mae: 16.2023 - val_loss: 475.0479 - val_mae: 16.8638\n",
      "Epoch 158/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 452.5754 - mae: 16.2594 - val_loss: 504.3078 - val_mae: 17.6693\n",
      "Epoch 159/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 471.8768 - mae: 16.7165 - val_loss: 490.2063 - val_mae: 17.0046\n",
      "Epoch 160/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 454.0894 - mae: 16.2587 - val_loss: 472.6548 - val_mae: 16.8405\n",
      "Epoch 161/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 443.1960 - mae: 16.2912 - val_loss: 482.4567 - val_mae: 16.9714\n",
      "Epoch 162/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 453.0599 - mae: 16.3339 - val_loss: 483.9511 - val_mae: 17.1191\n",
      "Epoch 163/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 443.3445 - mae: 16.2349 - val_loss: 478.2006 - val_mae: 16.9040\n",
      "Epoch 164/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 449.1793 - mae: 16.4723 - val_loss: 474.8141 - val_mae: 16.8246\n",
      "Epoch 165/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 440.4725 - mae: 16.3342 - val_loss: 499.0533 - val_mae: 17.1866\n",
      "Epoch 166/250\n",
      "191/191 [==============================] - 0s 977us/step - loss: 451.5709 - mae: 16.3191 - val_loss: 488.8019 - val_mae: 17.3830\n",
      "Epoch 167/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 455.9220 - mae: 16.3943 - val_loss: 478.9817 - val_mae: 16.6295\n",
      "Epoch 168/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 469.6406 - mae: 16.5908 - val_loss: 475.0475 - val_mae: 16.7834\n",
      "Epoch 169/250\n",
      "191/191 [==============================] - 0s 946us/step - loss: 438.3251 - mae: 16.1306 - val_loss: 481.4515 - val_mae: 17.0877\n",
      "Epoch 170/250\n",
      "191/191 [==============================] - 0s 945us/step - loss: 445.2726 - mae: 16.1642 - val_loss: 479.0703 - val_mae: 17.0269\n",
      "Epoch 171/250\n",
      "191/191 [==============================] - 0s 929us/step - loss: 452.9961 - mae: 16.2770 - val_loss: 494.5747 - val_mae: 17.0306\n",
      "Epoch 172/250\n",
      "191/191 [==============================] - 0s 919us/step - loss: 446.2612 - mae: 16.2241 - val_loss: 483.2338 - val_mae: 16.8947\n",
      "Epoch 173/250\n",
      "191/191 [==============================] - 0s 962us/step - loss: 445.4066 - mae: 16.2655 - val_loss: 470.8829 - val_mae: 16.7585\n",
      "Epoch 174/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 469.7587 - mae: 16.3934 - val_loss: 480.7080 - val_mae: 16.8876\n",
      "Epoch 175/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 433.8871 - mae: 16.0888 - val_loss: 479.0259 - val_mae: 16.8232\n",
      "Epoch 176/250\n",
      "191/191 [==============================] - 0s 964us/step - loss: 445.7079 - mae: 16.1819 - val_loss: 500.0006 - val_mae: 17.6784\n",
      "Epoch 177/250\n",
      "191/191 [==============================] - 0s 934us/step - loss: 434.5390 - mae: 16.0978 - val_loss: 481.2341 - val_mae: 16.9409\n",
      "Epoch 178/250\n",
      "191/191 [==============================] - 0s 927us/step - loss: 457.5845 - mae: 16.3160 - val_loss: 473.6354 - val_mae: 16.9248\n",
      "Epoch 179/250\n",
      "191/191 [==============================] - 0s 943us/step - loss: 446.8746 - mae: 16.2130 - val_loss: 471.8648 - val_mae: 16.9513\n",
      "Epoch 180/250\n",
      "191/191 [==============================] - 0s 953us/step - loss: 436.3250 - mae: 16.0849 - val_loss: 477.9336 - val_mae: 16.8949\n",
      "Epoch 181/250\n",
      "191/191 [==============================] - 0s 947us/step - loss: 462.9965 - mae: 16.2752 - val_loss: 471.3881 - val_mae: 16.6710\n",
      "Epoch 182/250\n",
      "191/191 [==============================] - 0s 952us/step - loss: 430.4323 - mae: 16.0468 - val_loss: 475.6782 - val_mae: 17.0304\n",
      "Epoch 183/250\n",
      "191/191 [==============================] - 0s 933us/step - loss: 445.3288 - mae: 16.1555 - val_loss: 478.1703 - val_mae: 16.8262\n",
      "Epoch 184/250\n",
      "191/191 [==============================] - 0s 986us/step - loss: 430.7899 - mae: 16.0095 - val_loss: 479.3240 - val_mae: 16.8710\n",
      "Epoch 185/250\n",
      "191/191 [==============================] - 0s 954us/step - loss: 447.5495 - mae: 16.1558 - val_loss: 476.1237 - val_mae: 16.9084\n",
      "Epoch 186/250\n",
      "191/191 [==============================] - 0s 935us/step - loss: 440.6693 - mae: 16.2003 - val_loss: 496.4267 - val_mae: 17.0203\n",
      "Epoch 187/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 460.5563 - mae: 16.3958 - val_loss: 477.0011 - val_mae: 16.8791\n",
      "Epoch 188/250\n",
      "191/191 [==============================] - 0s 953us/step - loss: 445.8535 - mae: 16.2555 - val_loss: 479.8316 - val_mae: 16.7108\n",
      "Epoch 189/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 453.6675 - mae: 16.3029 - val_loss: 484.8222 - val_mae: 16.9849\n",
      "Epoch 190/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 444.7342 - mae: 16.2160 - val_loss: 482.7958 - val_mae: 16.9738\n",
      "Epoch 191/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 442.1647 - mae: 16.0647 - val_loss: 479.7212 - val_mae: 16.8830\n",
      "Epoch 192/250\n",
      "191/191 [==============================] - 0s 996us/step - loss: 437.3231 - mae: 16.1089 - val_loss: 477.4073 - val_mae: 16.9612\n",
      "Epoch 193/250\n",
      "191/191 [==============================] - 0s 944us/step - loss: 442.7768 - mae: 16.0849 - val_loss: 479.9196 - val_mae: 17.0606\n",
      "Epoch 194/250\n",
      "191/191 [==============================] - 0s 960us/step - loss: 440.6827 - mae: 16.0818 - val_loss: 472.2542 - val_mae: 16.9044\n",
      "Epoch 195/250\n",
      "191/191 [==============================] - 0s 948us/step - loss: 446.8773 - mae: 16.2813 - val_loss: 480.8773 - val_mae: 16.7386\n",
      "Epoch 196/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 432.9408 - mae: 15.9865 - val_loss: 507.3530 - val_mae: 17.6822\n",
      "Epoch 197/250\n",
      "191/191 [==============================] - 0s 940us/step - loss: 448.9366 - mae: 16.2230 - val_loss: 473.9264 - val_mae: 16.8786\n",
      "Epoch 198/250\n",
      "191/191 [==============================] - 0s 983us/step - loss: 441.9161 - mae: 16.1162 - val_loss: 472.7734 - val_mae: 17.0143\n",
      "Epoch 199/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 436.9098 - mae: 16.0538 - val_loss: 467.8070 - val_mae: 16.8044\n",
      "Epoch 200/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 430.0925 - mae: 15.9565 - val_loss: 473.4671 - val_mae: 16.7891\n",
      "Epoch 201/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 436.5045 - mae: 16.0954 - val_loss: 478.5661 - val_mae: 16.7887\n",
      "Epoch 202/250\n",
      "191/191 [==============================] - 0s 944us/step - loss: 442.0178 - mae: 16.1146 - val_loss: 467.1854 - val_mae: 16.8280\n",
      "Epoch 203/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 445.1338 - mae: 16.2870 - val_loss: 481.0380 - val_mae: 16.7933\n",
      "Epoch 204/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 422.9775 - mae: 15.9248 - val_loss: 466.0168 - val_mae: 16.6150\n",
      "Epoch 205/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 439.6105 - mae: 16.1955 - val_loss: 475.0322 - val_mae: 16.8665\n",
      "Epoch 206/250\n",
      "191/191 [==============================] - 0s 967us/step - loss: 429.1323 - mae: 16.0125 - val_loss: 474.5283 - val_mae: 16.8822\n",
      "Epoch 207/250\n",
      "191/191 [==============================] - 0s 936us/step - loss: 429.9142 - mae: 16.0194 - val_loss: 469.1823 - val_mae: 16.7064\n",
      "Epoch 208/250\n",
      "191/191 [==============================] - 0s 951us/step - loss: 442.2076 - mae: 16.0463 - val_loss: 467.3227 - val_mae: 16.8230\n",
      "Epoch 209/250\n",
      "191/191 [==============================] - 0s 992us/step - loss: 426.0742 - mae: 15.7998 - val_loss: 467.0799 - val_mae: 16.8214\n",
      "Epoch 210/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 428.6020 - mae: 16.0033 - val_loss: 480.9623 - val_mae: 16.7992\n",
      "Epoch 211/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 445.0507 - mae: 16.1243 - val_loss: 476.2879 - val_mae: 16.7228\n",
      "Epoch 212/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 434.4866 - mae: 15.9242 - val_loss: 496.0229 - val_mae: 17.4668\n",
      "Epoch 213/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 455.4182 - mae: 16.3680 - val_loss: 471.3540 - val_mae: 16.8374\n",
      "Epoch 214/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 429.0040 - mae: 15.9549 - val_loss: 472.4144 - val_mae: 16.8422\n",
      "Epoch 215/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 423.7652 - mae: 15.9371 - val_loss: 471.7647 - val_mae: 16.9052\n",
      "Epoch 216/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 445.9035 - mae: 16.0918 - val_loss: 465.2184 - val_mae: 16.6188\n",
      "Epoch 217/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 440.7128 - mae: 16.1014 - val_loss: 484.8438 - val_mae: 17.0478\n",
      "Epoch 218/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 432.6085 - mae: 16.0359 - val_loss: 468.9950 - val_mae: 16.7958\n",
      "Epoch 219/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 442.7981 - mae: 16.1557 - val_loss: 472.8934 - val_mae: 17.0667\n",
      "Epoch 220/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 431.7399 - mae: 15.9547 - val_loss: 467.5870 - val_mae: 16.7951\n",
      "Epoch 221/250\n",
      "191/191 [==============================] - 0s 999us/step - loss: 426.4780 - mae: 15.9064 - val_loss: 468.6076 - val_mae: 16.8207\n",
      "Epoch 222/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 442.6442 - mae: 16.1163 - val_loss: 474.8044 - val_mae: 16.6799\n",
      "Epoch 223/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 432.6506 - mae: 15.9251 - val_loss: 466.6625 - val_mae: 16.6640\n",
      "Epoch 224/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 433.0369 - mae: 15.9656 - val_loss: 479.6360 - val_mae: 17.1190\n",
      "Epoch 225/250\n",
      "191/191 [==============================] - 0s 949us/step - loss: 439.6300 - mae: 16.1648 - val_loss: 477.7377 - val_mae: 16.9703\n",
      "Epoch 226/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 431.8252 - mae: 16.0233 - val_loss: 470.7150 - val_mae: 16.7564\n",
      "Epoch 227/250\n",
      "191/191 [==============================] - 0s 965us/step - loss: 426.8672 - mae: 15.9360 - val_loss: 470.5785 - val_mae: 17.0344\n",
      "Epoch 228/250\n",
      "191/191 [==============================] - 0s 996us/step - loss: 435.6349 - mae: 15.9663 - val_loss: 481.2040 - val_mae: 17.0228\n",
      "Epoch 229/250\n",
      "191/191 [==============================] - 0s 990us/step - loss: 428.1663 - mae: 16.0264 - val_loss: 464.7137 - val_mae: 16.7297\n",
      "Epoch 230/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 438.5807 - mae: 16.0048 - val_loss: 467.4388 - val_mae: 16.8051\n",
      "Epoch 231/250\n",
      "191/191 [==============================] - 0s 972us/step - loss: 423.5938 - mae: 15.8451 - val_loss: 485.8582 - val_mae: 17.0057\n",
      "Epoch 232/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 419.2268 - mae: 15.8064 - val_loss: 468.5997 - val_mae: 16.7512\n",
      "Epoch 233/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 433.3073 - mae: 16.0649 - val_loss: 472.6965 - val_mae: 16.7549\n",
      "Epoch 234/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 426.5543 - mae: 15.7464 - val_loss: 486.6158 - val_mae: 17.1950\n",
      "Epoch 235/250\n",
      "191/191 [==============================] - 0s 969us/step - loss: 434.0428 - mae: 15.9477 - val_loss: 459.5807 - val_mae: 16.6400\n",
      "Epoch 236/250\n",
      "191/191 [==============================] - 0s 966us/step - loss: 435.0001 - mae: 15.9306 - val_loss: 462.1811 - val_mae: 16.7190\n",
      "Epoch 237/250\n",
      "191/191 [==============================] - 0s 945us/step - loss: 424.0474 - mae: 15.7245 - val_loss: 496.1207 - val_mae: 17.1185\n",
      "Epoch 238/250\n",
      "191/191 [==============================] - 0s 956us/step - loss: 447.3152 - mae: 15.9453 - val_loss: 468.5814 - val_mae: 16.8717\n",
      "Epoch 239/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 419.5449 - mae: 15.7667 - val_loss: 478.9538 - val_mae: 16.8376\n",
      "Epoch 240/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 417.6836 - mae: 15.7536 - val_loss: 460.2169 - val_mae: 16.5821\n",
      "Epoch 241/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 417.4694 - mae: 15.5787 - val_loss: 462.9805 - val_mae: 16.7847\n",
      "Epoch 242/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 424.0523 - mae: 15.7754 - val_loss: 462.4565 - val_mae: 16.5883\n",
      "Epoch 243/250\n",
      "191/191 [==============================] - 0s 956us/step - loss: 427.9639 - mae: 15.9372 - val_loss: 482.8105 - val_mae: 16.9113\n",
      "Epoch 244/250\n",
      "191/191 [==============================] - 0s 977us/step - loss: 413.8142 - mae: 15.7095 - val_loss: 471.9855 - val_mae: 16.7201\n",
      "Epoch 245/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 425.4969 - mae: 15.8653 - val_loss: 465.6466 - val_mae: 16.6677\n",
      "Epoch 246/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 417.1691 - mae: 15.7245 - val_loss: 464.2484 - val_mae: 16.7215\n",
      "Epoch 247/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 422.4456 - mae: 15.7786 - val_loss: 471.4530 - val_mae: 16.6754\n",
      "Epoch 248/250\n",
      "191/191 [==============================] - 0s 959us/step - loss: 410.3306 - mae: 15.6173 - val_loss: 469.8896 - val_mae: 16.7585\n",
      "Epoch 249/250\n",
      "191/191 [==============================] - 0s 988us/step - loss: 435.6543 - mae: 15.8884 - val_loss: 465.0430 - val_mae: 16.5035\n",
      "Epoch 250/250\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 413.2546 - mae: 15.5818 - val_loss: 462.6320 - val_mae: 16.5930\n"
     ]
    }
   ],
   "source": [
    "# making no changes, I want the NNet baseline\n",
    "# Insert model here...\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (12,)))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1, activation = None))\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])\n",
    "\n",
    "# fit the model\n",
    "results = model.fit(X_train_sc, y_train,\n",
    "                    batch_size = 100,\n",
    "                    epochs = 250, \n",
    "                    validation_data = (X_test_sc, y_test),\n",
    "                    verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ca9576a7bc7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m pipe = Pipeline([\n\u001b[1;32m      3\u001b[0m     \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../app/resources/NYC-st-app-model_h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;31m#   not to any other argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# - setting the SavedModel saving spec.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_out_first_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_split_out_first_arg\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   3048\u001b[0m           'The first argument to `Layer.call` must always be passed.')\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "# save model for Streamlit app\n",
    "pipe = Pipeline([\n",
    "    StandardScaler(),\n",
    "    model.predict()\n",
    "])\n",
    "model.save('../app/resources/NYC-st-app-model_h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.161718368530273"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history['mae'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.74115753173828"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history['val_mae'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the loss\n",
    "train_loss = results.history['loss']\n",
    "test_loss =  results.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Training loss', color='navy')\n",
    "plt.plot(test_loss, label='Testing loss', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error drops this into the range of being within 21 calls per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising mean accuracy error\n",
    "train_mae = results.history['mae']\n",
    "test_mae =  results.history['val_mae']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_mae, label='Training MAE', color='navy')\n",
    "plt.plot(test_mae, label='Testing MAE', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE results are interesting since this would suggest we can get within 17 calls for predictions BUT it is important to note that this does not penalize large errors as harshly as RMSE does.  Since we want to avoid large mistakes (we're talking emergency/life and death situations) we do want to use RMSE instead of MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_sc)\n",
    "y_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_calls</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6367.000000</td>\n",
       "      <td>6367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>136.157845</td>\n",
       "      <td>134.268570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.344129</td>\n",
       "      <td>49.656021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>50.258030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.880684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>122.294922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>182.385872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>261.466064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_calls        preds\n",
       "count  6367.000000  6367.000000\n",
       "mean    136.157845   134.268570\n",
       "std      54.344129    49.656021\n",
       "min      36.000000    50.258030\n",
       "25%      88.000000    88.880684\n",
       "50%     127.000000   122.294922\n",
       "75%     185.000000   182.385872\n",
       "max     377.000000   261.466064"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df['preds'] = preds\n",
    "y_df['error'] = (y_df['preds'] - y_df['num_calls'])\n",
    "y_df[['num_calls', 'preds']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Interesting thing to note here (at least I think so) is that the mean and std are very close between num_calls and preds but preds do not even come close to the top end of actual maximum num_calls being off by a full 120 calls.  Other wise this would seem to indicate a pretty solid result for predicting call volumes.  Outliers will be outliers and we will never get close to seeing a disaster scenario coming but hopefully this will account for most situations within what we might consider the norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0.8676335518449162\n",
      "Testing: 0.840234343111754\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train_sc)\n",
    "\n",
    "training =  r2_score(y_train, train_preds)\n",
    "testing = r2_score(y_test, preds)\n",
    "\n",
    "print(f'Training: {training}')\n",
    "print(f'Testing: {testing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.719267252428562, 21.72002101590659)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(y_train, train_preds)), sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Recurrent Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/final_calls_weather_tfk.csv')\n",
    "\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "df.set_index(df['DATE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['num_calls', 'BROOKLYN', 'BRONX' ,'MANHATTAN', \n",
    "                       'UNKNOWN','Unnamed: 0', 'RICHMOND / STATEN ISLAND','DATE', 'Unnamed: 0.1'\n",
    "                       ])\n",
    "y = df['num_calls']\n",
    "\n",
    "X = pd.get_dummies(X, columns = ['STATION'])\n",
    "X = pd.get_dummies(X, columns = ['NAME'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = TimeseriesGenerator(X_train_sc, y_train, length = 3, batch_size = 64)\n",
    "\n",
    "test_sequences = TimeseriesGenerator(X_test_sc, y_test, length=3, batch_size = 64)\n",
    "\n",
    "d =train_sequences[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = EarlyStopping(monitor = 'mae', patience = 10, min_delta = .01)\n",
    "\n",
    "# set up structure\n",
    "model = Sequential()\n",
    "model.add(GRU(8, input_shape=d, return_sequences=True))\n",
    "model.add(GRU(8, return_sequences=False))\n",
    "\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=Adam(lr=.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "results = model.fit(train_sequences, \n",
    "          epochs = 100,\n",
    "          batch_size = 256,\n",
    "          validation_data = test_sequences,\n",
    "          callbacks = stop,\n",
    "                   verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mae = results.history['loss']\n",
    "test_mae =  results.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_mae, label='Training Loss', color='navy')\n",
    "plt.plot(test_mae, label='Testing Loss', color='skyblue')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
