{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the new hourly counts dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25465 entries, 0 to 25464\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                25465 non-null  int64  \n",
      " 1   year                      25465 non-null  int64  \n",
      " 2   month                     25465 non-null  int64  \n",
      " 3   day                       25465 non-null  int64  \n",
      " 4   hour                      25465 non-null  int64  \n",
      " 5   num_calls                 25465 non-null  int64  \n",
      " 6   BRONX                     25465 non-null  int64  \n",
      " 7   BROOKLYN                  25465 non-null  int64  \n",
      " 8   MANHATTAN                 25465 non-null  int64  \n",
      " 9   QUEENS                    25465 non-null  int64  \n",
      " 10  RICHMOND / STATEN ISLAND  25465 non-null  int64  \n",
      " 11  UNKNOWN                   25465 non-null  int64  \n",
      " 12  STATION                   25465 non-null  object \n",
      " 13  NAME                      25465 non-null  object \n",
      " 14  DATE                      25465 non-null  object \n",
      " 15  AWND                      25241 non-null  float64\n",
      " 16  PRCP                      25465 non-null  float64\n",
      " 17  SNOW                      25465 non-null  float64\n",
      " 18  SNWD                      25465 non-null  float64\n",
      " 19  TMAX                      25465 non-null  float64\n",
      " 20  TMIN                      25465 non-null  float64\n",
      " 21  TAVG_CALC                 25465 non-null  float64\n",
      " 22  Incidences                25465 non-null  int64  \n",
      "dtypes: float64(7), int64(13), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/updated_calls_weather_tfk.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn tools:\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# sklearn models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up X and y, do train test split, and scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['year', 'month', 'day', 'hour', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'TAVG_CALC']]\n",
    "y = df['num_calls']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE, call volume = 136.38548539114043\n",
      "R2:  Train: 0.0, Test: -1.7549351112977618e-05\n",
      "RMS: Train: 54.20031558657461, Test: 54.340338222301554\n"
     ]
    }
   ],
   "source": [
    "m = y_train.mean()\n",
    "baseline_train = [m for y in y_train]\n",
    "baseline_test  = [m for y in y_test]\n",
    "R20 = r2_score(y_train,baseline_train)\n",
    "R21 = r2_score(y_test,baseline_test)\n",
    "RMS0= mean_squared_error(y_train,baseline_train,squared=False)\n",
    "RMS1= mean_squared_error(y_test, baseline_test, squared=False)\n",
    "print(f'BASELINE, call volume = {m}')\n",
    "print(f'R2:  Train: {R20}, Test: {R21}')\n",
    "print(f'RMS: Train: {RMS0}, Test: {RMS1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  Train: 0.4032671580422418, Test: 0.4052229110923856\n",
      "RMS: Train: 40.255567545763256, Test: 40.11893624015415\n"
     ]
    }
   ],
   "source": [
    "lr1 = LinearRegression()\n",
    "lr1.fit(X_train,y_train)\n",
    "R20 = lr1.score(X_train,y_train)\n",
    "R21 = lr1.score(X_test,y_test)\n",
    "RMS0= mean_squared_error(y_train,lr1.predict(X_train),squared=False)\n",
    "RMS1= mean_squared_error(y_test, lr1.predict(X_test), squared=False)\n",
    "print(f'R2:  Train: {R20}, Test: {R21}')\n",
    "print(f'RMS: Train: {RMS0}, Test: {RMS1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know several features have non-linear interactions with num_calls. Let's try Polynomial Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Features of Degree 2:\n",
      "R2:  Train: 0.5116451501308716, Test: 0.5154334226943383\n",
      "RMS: Train: 36.416963952985625, Test: 36.211708980596406\n",
      "\n",
      "Polynomial Features of Degree 3:\n",
      "R2:  Train: 0.6730675026092716, Test: 0.6749179787498814\n",
      "RMS: Train: 29.79648465778076, Test: 29.659837639626755\n",
      "\n",
      "Polynomial Features of Degree 4:\n",
      "R2:  Train: 0.7600247774298331, Test: 0.7575773505001402\n",
      "RMS: Train: 25.52814072703261, Test: 25.612908048162943\n"
     ]
    }
   ],
   "source": [
    "for n in range(2,5):\n",
    "    print()\n",
    "    print(f'Polynomial Features of Degree {n}:')\n",
    "    pf = PolynomialFeatures(degree=n)\n",
    "    PF_train = pf.fit_transform(Z_train)\n",
    "    PF_test  = pf.transform(Z_test)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(PF_train,y_train)\n",
    "    R20 = lr2.score(PF_train,y_train)\n",
    "    R21 = lr2.score(PF_test,y_test)\n",
    "    RMS0= mean_squared_error(y_train,lr2.predict(PF_train),squared=False)\n",
    "    RMS1= mean_squared_error(y_test, lr2.predict(PF_test), squared=False)\n",
    "    print(f'R2:  Train: {R20}, Test: {R21}')\n",
    "    print(f'RMS: Train: {RMS0}, Test: {RMS1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Features definitely helped!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net, first attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "257/257 [==============================] - 5s 12ms/step - loss: 25332.5375 - mae: 149.3183 - val_loss: 3636.4377 - val_mae: 48.2211\n",
      "Epoch 2/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 2998.6525 - mae: 43.7047 - val_loss: 2260.6738 - val_mae: 38.1405\n",
      "Epoch 3/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 2137.0729 - mae: 37.4904 - val_loss: 1978.6080 - val_mae: 36.0069\n",
      "Epoch 4/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 1927.1506 - mae: 35.8471 - val_loss: 1853.7872 - val_mae: 35.0535\n",
      "Epoch 5/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 1798.9916 - mae: 34.7096 - val_loss: 1791.2189 - val_mae: 34.5871\n",
      "Epoch 6/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 1762.9768 - mae: 34.3062 - val_loss: 1745.7385 - val_mae: 34.20831763.1784 - mae: 34.305\n",
      "Epoch 7/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 1730.6924 - mae: 34.0664 - val_loss: 1713.9470 - val_mae: 33.9207\n",
      "Epoch 8/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 1698.1086 - mae: 33.7934 - val_loss: 1686.8331 - val_mae: 33.6656\n",
      "Epoch 9/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 1666.1286 - mae: 33.5068 - val_loss: 1666.0243 - val_mae: 33.4504\n",
      "Epoch 10/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 1660.3495 - mae: 33.1711 - val_loss: 1627.8752 - val_mae: 33.0938\n",
      "Epoch 11/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 1615.1556 - mae: 32.9429 - val_loss: 1502.5818 - val_mae: 31.7465\n",
      "Epoch 12/100\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 1434.4991 - mae: 30.9128 - val_loss: 1141.0342 - val_mae: 27.4162\n",
      "Epoch 13/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 1059.1170 - mae: 26.1618 - val_loss: 827.9985 - val_mae: 23.0144\n",
      "Epoch 14/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 809.5286 - mae: 22.6950 - val_loss: 753.5938 - val_mae: 21.6885\n",
      "Epoch 15/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 767.7526 - mae: 21.7637 - val_loss: 710.0941 - val_mae: 21.0079\n",
      "Epoch 16/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 699.1227 - mae: 20.9147 - val_loss: 680.3904 - val_mae: 20.5099\n",
      "Epoch 17/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 696.1618 - mae: 20.4638 - val_loss: 663.5403 - val_mae: 20.1799\n",
      "Epoch 18/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 676.7729 - mae: 20.1794 - val_loss: 650.1054 - val_mae: 20.0106\n",
      "Epoch 19/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 664.2337 - mae: 19.9020 - val_loss: 639.9280 - val_mae: 19.8116\n",
      "Epoch 20/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 645.7103 - mae: 19.6111 - val_loss: 632.4804 - val_mae: 19.6756\n",
      "Epoch 21/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 636.6791 - mae: 19.5750 - val_loss: 629.7032 - val_mae: 19.5074\n",
      "Epoch 22/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 642.7709 - mae: 19.5456 - val_loss: 624.7397 - val_mae: 19.5684\n",
      "Epoch 23/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 626.4731 - mae: 19.4500 - val_loss: 614.2152 - val_mae: 19.2964\n",
      "Epoch 24/100\n",
      "257/257 [==============================] - 2s 9ms/step - loss: 627.3188 - mae: 19.2979 - val_loss: 606.8610 - val_mae: 19.1245\n",
      "Epoch 25/100\n",
      "257/257 [==============================] - 3s 11ms/step - loss: 613.9341 - mae: 19.1485 - val_loss: 602.2754 - val_mae: 19.0854\n",
      "Epoch 26/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 610.0476 - mae: 19.0589 - val_loss: 598.4112 - val_mae: 18.9366\n",
      "Epoch 27/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 597.6047 - mae: 19.0542 - val_loss: 591.6932 - val_mae: 18.8569\n",
      "Epoch 28/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 593.1078 - mae: 18.9388 - val_loss: 587.5436 - val_mae: 18.7842\n",
      "Epoch 29/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 591.0956 - mae: 18.9612 - val_loss: 588.0430 - val_mae: 18.7918\n",
      "Epoch 30/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 603.6760 - mae: 18.8714 - val_loss: 581.4021 - val_mae: 18.6704\n",
      "Epoch 31/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 601.2576 - mae: 18.7736 - val_loss: 580.8809 - val_mae: 18.6342\n",
      "Epoch 32/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 598.7665 - mae: 18.7829 - val_loss: 579.0861 - val_mae: 18.6974\n",
      "Epoch 33/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 578.5671 - mae: 18.6742 - val_loss: 575.1967 - val_mae: 18.6053\n",
      "Epoch 34/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 612.5907 - mae: 18.6871 - val_loss: 578.2821 - val_mae: 18.7145\n",
      "Epoch 35/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 583.3501 - mae: 18.6709 - val_loss: 574.2170 - val_mae: 18.6043\n",
      "Epoch 36/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 577.8736 - mae: 18.5415 - val_loss: 574.0198 - val_mae: 18.4619\n",
      "Epoch 37/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 595.3489 - mae: 18.6825 - val_loss: 574.3530 - val_mae: 18.5784\n",
      "Epoch 38/100\n",
      "257/257 [==============================] - 3s 10ms/step - loss: 572.4730 - mae: 18.5473 - val_loss: 569.2347 - val_mae: 18.4397\n",
      "Epoch 39/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 589.0358 - mae: 18.5192 - val_loss: 570.8682 - val_mae: 18.5747\n",
      "Epoch 40/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 592.0684 - mae: 18.5939 - val_loss: 567.9310 - val_mae: 18.4022\n",
      "Epoch 41/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 575.0095 - mae: 18.4807 - val_loss: 568.3931 - val_mae: 18.4786\n",
      "Epoch 42/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 565.1840 - mae: 18.4153 - val_loss: 565.5928 - val_mae: 18.4122\n",
      "Epoch 43/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 583.2551 - mae: 18.6013 - val_loss: 568.3945 - val_mae: 18.3553\n",
      "Epoch 44/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 569.0398 - mae: 18.4445 - val_loss: 565.5330 - val_mae: 18.4379\n",
      "Epoch 45/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 567.8322 - mae: 18.4888 - val_loss: 563.9611 - val_mae: 18.3916\n",
      "Epoch 46/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 579.0380 - mae: 18.5335 - val_loss: 563.2677 - val_mae: 18.3860\n",
      "Epoch 47/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 579.7926 - mae: 18.4085 - val_loss: 562.9434 - val_mae: 18.3820\n",
      "Epoch 48/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 587.5101 - mae: 18.4338 - val_loss: 561.8400 - val_mae: 18.3825\n",
      "Epoch 49/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 560.7618 - mae: 18.3798 - val_loss: 561.1351 - val_mae: 18.3073\n",
      "Epoch 50/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 563.8599 - mae: 18.4178 - val_loss: 566.7056 - val_mae: 18.3445\n",
      "Epoch 51/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 558.9248 - mae: 18.3084 - val_loss: 561.6218 - val_mae: 18.2920\n",
      "Epoch 52/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 587.9672 - mae: 18.4411 - val_loss: 565.4567 - val_mae: 18.4562\n",
      "Epoch 53/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 556.1905 - mae: 18.3211 - val_loss: 562.3024 - val_mae: 18.4390\n",
      "Epoch 54/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 555.3656 - mae: 18.2926 - val_loss: 564.8740 - val_mae: 18.5237\n",
      "Epoch 55/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 568.2627 - mae: 18.2961 - val_loss: 561.4144 - val_mae: 18.3788\n",
      "Epoch 56/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 565.9760 - mae: 18.2422 - val_loss: 561.2264 - val_mae: 18.3824\n",
      "Epoch 57/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 549.4786 - mae: 18.2571 - val_loss: 562.5833 - val_mae: 18.4542\n",
      "Epoch 58/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 556.4856 - mae: 18.3458 - val_loss: 561.3091 - val_mae: 18.3220\n",
      "Epoch 59/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 566.3311 - mae: 18.2578 - val_loss: 565.8564 - val_mae: 18.2903\n",
      "Epoch 60/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 551.3527 - mae: 18.1758 - val_loss: 558.7081 - val_mae: 18.2919\n",
      "Epoch 61/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 597.5656 - mae: 18.4175 - val_loss: 559.1572 - val_mae: 18.3359\n",
      "Epoch 62/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 565.5285 - mae: 18.4106 - val_loss: 561.2081 - val_mae: 18.2490\n",
      "Epoch 63/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 564.1201 - mae: 18.1812 - val_loss: 557.8663 - val_mae: 18.2922\n",
      "Epoch 64/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 560.7674 - mae: 18.2510 - val_loss: 562.3656 - val_mae: 18.3707\n",
      "Epoch 65/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 560.5322 - mae: 18.2909 - val_loss: 561.5294 - val_mae: 18.4022\n",
      "Epoch 66/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 550.7367 - mae: 18.1926 - val_loss: 560.6608 - val_mae: 18.2944\n",
      "Epoch 67/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 583.2294 - mae: 18.3729 - val_loss: 559.4058 - val_mae: 18.3167\n",
      "Epoch 68/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 569.5687 - mae: 18.2397 - val_loss: 560.0949 - val_mae: 18.3985\n",
      "Epoch 69/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 555.3243 - mae: 18.1952 - val_loss: 557.1756 - val_mae: 18.2734\n",
      "Epoch 70/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 574.9415 - mae: 18.3222 - val_loss: 556.5430 - val_mae: 18.2349\n",
      "Epoch 71/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 558.6385 - mae: 18.1716 - val_loss: 556.4238 - val_mae: 18.2631\n",
      "Epoch 72/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 550.0571 - mae: 18.2024 - val_loss: 559.7283 - val_mae: 18.3358\n",
      "Epoch 73/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 563.9490 - mae: 18.2252 - val_loss: 558.8105 - val_mae: 18.2426\n",
      "Epoch 74/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 568.3879 - mae: 18.2009 - val_loss: 556.4156 - val_mae: 18.3131\n",
      "Epoch 75/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 559.9281 - mae: 18.2543 - val_loss: 556.3444 - val_mae: 18.2561\n",
      "Epoch 76/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 566.4419 - mae: 18.3286 - val_loss: 560.0995 - val_mae: 18.3872\n",
      "Epoch 77/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 577.6241 - mae: 18.3258 - val_loss: 559.9439 - val_mae: 18.2986\n",
      "Epoch 78/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 553.9205 - mae: 18.1652 - val_loss: 558.1439 - val_mae: 18.3918\n",
      "Epoch 79/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 558.7651 - mae: 18.2108 - val_loss: 556.2120 - val_mae: 18.2307\n",
      "Epoch 80/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 580.1517 - mae: 18.2573 - val_loss: 556.8364 - val_mae: 18.2403\n",
      "Epoch 81/100\n",
      "257/257 [==============================] - 2s 8ms/step - loss: 566.4659 - mae: 18.2928 - val_loss: 556.5480 - val_mae: 18.2725\n",
      "Epoch 82/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 582.3016 - mae: 18.2459 - val_loss: 556.4840 - val_mae: 18.2325\n",
      "Epoch 83/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 556.4548 - mae: 18.1829 - val_loss: 555.8604 - val_mae: 18.2090\n",
      "Epoch 84/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 585.7167 - mae: 18.3750 - val_loss: 562.1125 - val_mae: 18.4008\n",
      "Epoch 85/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 562.8528 - mae: 18.1337 - val_loss: 557.5356 - val_mae: 18.3031\n",
      "Epoch 86/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 566.3077 - mae: 18.1698 - val_loss: 559.7455 - val_mae: 18.3820\n",
      "Epoch 87/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 580.8550 - mae: 18.3212 - val_loss: 556.6069 - val_mae: 18.1920\n",
      "Epoch 88/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 565.8369 - mae: 18.2838 - val_loss: 554.3671 - val_mae: 18.1737\n",
      "Epoch 89/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 572.0088 - mae: 18.2639 - val_loss: 555.6887 - val_mae: 18.2441\n",
      "Epoch 90/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 553.7874 - mae: 18.1287 - val_loss: 555.2829 - val_mae: 18.2110\n",
      "Epoch 91/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 571.6416 - mae: 18.1526 - val_loss: 553.9012 - val_mae: 18.1461\n",
      "Epoch 92/100\n",
      "257/257 [==============================] - 1s 6ms/step - loss: 562.4598 - mae: 18.2045 - val_loss: 555.6772 - val_mae: 18.2990\n",
      "Epoch 93/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 573.7471 - mae: 18.1635 - val_loss: 555.8124 - val_mae: 18.3043\n",
      "Epoch 94/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 550.7754 - mae: 18.1970 - val_loss: 557.6400 - val_mae: 18.3100\n",
      "Epoch 95/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 562.4813 - mae: 18.2180 - val_loss: 558.0241 - val_mae: 18.3508\n",
      "Epoch 96/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 565.1806 - mae: 18.2404 - val_loss: 554.8245 - val_mae: 18.2155\n",
      "Epoch 97/100\n",
      "257/257 [==============================] - 2s 7ms/step - loss: 555.3355 - mae: 18.2657 - val_loss: 553.8173 - val_mae: 18.1293\n",
      "Epoch 98/100\n",
      "257/257 [==============================] - 2s 6ms/step - loss: 547.8420 - mae: 18.1343 - val_loss: 562.2639 - val_mae: 18.4456\n",
      "Epoch 99/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 554.6854 - mae: 18.0887 - val_loss: 562.8139 - val_mae: 18.3479\n",
      "Epoch 100/100\n",
      "257/257 [==============================] - 1s 5ms/step - loss: 552.4988 - mae: 18.1289 - val_loss: 553.6754 - val_mae: 18.2350\n"
     ]
    }
   ],
   "source": [
    "#set random state for reproducability:\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=Z_train.shape[1], \n",
    "                    activation='relu'))\n",
    "model.add(Dense(16,  \n",
    "                    activation='relu'))\n",
    "model.add(Dense(8,  \n",
    "                    activation='relu',))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "\n",
    "results = model.fit(Z_train, y_train, epochs=100, batch_size=256, \\\n",
    "                            validation_data=(Z_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_nn0 = model.predict(Z_train)\n",
    "preds_nn1 = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Model:\n",
      "R2:  Train: 0.7600247774298331, Test: 0.7575773505001402\n",
      "RMS: Train: 25.52814072703261, Test: 25.612908048162943\n"
     ]
    }
   ],
   "source": [
    "R20 = lr2.score(PF_train,y_train)\n",
    "R21 = lr2.score(PF_test,y_test)\n",
    "RMS0= mean_squared_error(y_train,lr2.predict(PF_train),squared=False)\n",
    "RMS1= mean_squared_error(y_test, lr2.predict(PF_test), squared=False)\n",
    "print('Best Linear Model:')\n",
    "print(f'R2:  Train: {R20}, Test: {R21}')\n",
    "print(f'RMS: Train: {RMS0}, Test: {RMS1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net Model:\n",
      "R2:  Train: 0.7941486260633767, Test: 0.7953976735485776\n",
      "RMS: Train: 23.64356000382835, Test: 23.530306132286523\n"
     ]
    }
   ],
   "source": [
    "R20 = r2_score(y_train,preds_nn0)\n",
    "R21 = r2_score(y_test, preds_nn1)\n",
    "RMS0= mean_squared_error(y_train,preds_nn0,squared=False)\n",
    "RMS1= mean_squared_error(y_test, preds_nn1, squared=False)\n",
    "print('Neural Net Model:')\n",
    "print(f'R2:  Train: {R20}, Test: {R21}')\n",
    "print(f'RMS: Train: {RMS0}, Test: {RMS1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is definitely some room for improvement, and we should be able to get a good model from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
